{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1353041-d939-46a2-a2df-51fcd0bfc7dc",
   "metadata": {},
   "source": [
    "# Metal Music Sampling\n",
    "\n",
    "References: \n",
    "\n",
    "https://github.com/shubham3121/music-generation-using-rnn \n",
    "\n",
    "https://www.hackerearth.com/blog/developers/jazz-music-using-deep-learning/\n",
    "\n",
    "https://pyguitarpro.readthedocs.io/en/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f0e55-1e24-40ac-9b61-f29842f7c29e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38f669c-68f6-49ed-8f65-220e32b7e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import guitarpro\n",
    "from guitarpro import *\n",
    "from matplotlib import pyplot as plt\n",
    "import mgzip\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, LSTM, Dropout, Flatten\n",
    "\n",
    "from _Decompressor import SongWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4933987e-c8b5-491c-a232-08467deeb71c",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e408a14-c598-4145-a63e-f921a301ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 100\n",
    "\n",
    "as_fingerings = True\n",
    "\n",
    "\n",
    "# PITCH[i] = the pitch associated with midi note number i.\n",
    "# For example, PITCH[69] = 'A4'\n",
    "PITCH = {val : str(GuitarString(number=0, value=val)) for val in range(128)}\n",
    "# MIDI[string] = the midi number associated with the note described by string.\n",
    "# For example, MIDI['A4'] = 69.\n",
    "MIDI  = {str(GuitarString(number=0, value=val)) : val for val in range(128)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a36de-d670-41a6-981b-169519b21bba",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ef2eab-df6c-47b0-bcc8-41a7c205310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mgzip.open('data\\\\notes_data.pickle.gz', 'rb') as filepath:\n",
    "    notes = pickle.load(filepath)\n",
    "    note_to_int = pickle.load(filepath)\n",
    "    int_to_note = pickle.load(filepath)\n",
    "    n_vocab = pickle.load(filepath)\n",
    "\n",
    "with mgzip.open('data\\\\track_data.pickle.gz', 'rb') as filepath:\n",
    "    track_data = pickle.load(filepath)\n",
    "    \n",
    "#with mgzip.open('output\\\\generated_songs.pickle.gz', 'rb') as filepath:\n",
    "#    track_indices = pickle.load(filepath)\n",
    "#    tracks = pickle.load(filepath)\n",
    "\n",
    "model = keras.models.load_model('minigpt')\n",
    "\n",
    "ints = np.array([note_to_int[x] for x in notes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e3242e-9724-40a4-8ec9-9aa221f0d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "\n",
    "def generate_track(track_idx=None):\n",
    "    \n",
    "    if track_idx is None:\n",
    "        # Choose a random track\n",
    "        track_idx = np.random.choice(len(track_data))\n",
    "\n",
    "    # Get the note indices corresponding to the beginning and ending of the track\n",
    "    song_note_idx_first = track_data.loc[track_idx]['noteStartIdx']\n",
    "    song_note_idx_last = track_data.loc[track_idx+1]['noteStartIdx']\n",
    "\n",
    "    # Choose a random starting point within the track\n",
    "    start_idx = np.random.randint(low=song_note_idx_first,\n",
    "                                high=song_note_idx_last)\n",
    "\n",
    "    # Choose a number of initial notes to select from the track, at most 100.\n",
    "    #num_initial_notes = np.random.choice(min(100, song_note_idx_last - start_idx))\n",
    "    num_initial_notes = np.random.choice(min(100, song_note_idx_last - start_idx))\n",
    "\n",
    "    # Select the initial notes (tokens)\n",
    "    start_tokens = [_ for _ in ints[start_idx:start_idx+num_initial_notes]]\n",
    "\n",
    "\n",
    "    max_tokens = 100\n",
    "\n",
    "\n",
    "\n",
    "    def sample_from(logits, top_k=10):\n",
    "        logits, indices = tf.math.top_k(logits, k=top_k, sorted=True)\n",
    "        indices = np.asarray(indices).astype(\"int32\")\n",
    "        preds = keras.activations.softmax(tf.expand_dims(logits, 0))[0]\n",
    "        preds = np.asarray(preds).astype(\"float32\")\n",
    "        return np.random.choice(indices, p=preds)\n",
    "\n",
    "    num_tokens_generated = 0\n",
    "    tokens_generated = []\n",
    "\n",
    "    while num_tokens_generated <= max_tokens:\n",
    "        pad_len = maxlen - len(start_tokens)\n",
    "        sample_index = len(start_tokens) - 1\n",
    "        if pad_len < 0:\n",
    "            x = start_tokens[:maxlen]\n",
    "            sample_index = maxlen - 1\n",
    "        elif pad_len > 0:\n",
    "            x = start_tokens + [0] * pad_len\n",
    "        else:\n",
    "            x = start_tokens\n",
    "        x = np.array([x])\n",
    "        y, _ = model.predict(x)\n",
    "        sample_token = sample_from(y[0][sample_index])\n",
    "        tokens_generated.append(sample_token)\n",
    "        start_tokens.append(sample_token)\n",
    "        num_tokens_generated = len(tokens_generated)\n",
    "\n",
    "    generated_notes = [int_to_note[num] for num in np.concatenate((start_tokens, tokens_generated))]\n",
    "\n",
    "    return track_idx, generated_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82003860-de34-428f-b51d-cd607de1d9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:50<00:00, 11.04s/it]\n"
     ]
    }
   ],
   "source": [
    "NUM_TRACKS_TO_GENERATE = 10\n",
    "ARTIST = None\n",
    "\n",
    "\n",
    "track_indices = np.zeros(NUM_TRACKS_TO_GENERATE)\n",
    "tracks = np.zeros(NUM_TRACKS_TO_GENERATE, dtype=object)\n",
    "\n",
    "\n",
    "for i in tqdm(range(NUM_TRACKS_TO_GENERATE)):\n",
    "    if ARTIST is None:\n",
    "        idx, t = generate_track()\n",
    "    else:\n",
    "        idx, t = generate_track(track_idx=np.random.choice(list(track_data[track_data.artist==ARTIST].index)))\n",
    "    track_indices[i] = idx\n",
    "    tracks[i] = t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8333a8d8-c0cf-4f02-b754-398e78c2ace2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Note Generation Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5645634e-49b4-4941-901c-5690f9b09094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thirty_seconds_to_duration(count):\n",
    "    if count % 3 == 0:\n",
    "        # If the note is dotted, do 32 / (i * 2/3), and return isDotted = True.\n",
    "        return (48//count, True)\n",
    "    else:\n",
    "        # If the note is not dotted, to 32 / i, and return isDotted = False.\n",
    "        return (32//count, False)\n",
    "\n",
    "    \n",
    "def quantize_thirty_seconds(value):\n",
    "\n",
    "    # 32nd-note values of each fundamental type of note (not including 64th-notes, of course).\n",
    "    vals = np.array([32, # whole\n",
    "                     24, # dotted half\n",
    "                     16, # half\n",
    "                     12, # dotted quarter\n",
    "                     8,  # quarter\n",
    "                     6,  # dotted eigth\n",
    "                     4,  # eigth\n",
    "                     3,  # dotted sixteenth\n",
    "                     2,  # sixteenth\n",
    "                     1]) # thirty-second\n",
    "    \n",
    "    list_out = []\n",
    "\n",
    "    for v in vals:\n",
    "        if v <= value:\n",
    "            list_out.append(thirty_seconds_to_duration(v))\n",
    "            value -= v\n",
    "            \n",
    "    return np.array(list_out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def adjust_to_4_4(prediction_output):\n",
    "    '''\n",
    "    Adjust prediction output to be in 4/4 time.\n",
    "    Then, separate the beats into measures.\n",
    "    '''\n",
    "\n",
    "    # This will be the prediction output\n",
    "    new_prediction_output = []\n",
    "\n",
    "\n",
    "    time = 0\n",
    "    for beat in prediction_output:\n",
    "\n",
    "        # Calculate the fraction of a measure encompassed by the current beat / chord.\n",
    "        beat_time = (1 / beat[1]) * (1 + 0.5 * beat[2])\n",
    "\n",
    "        # Calculate the fraction of a measure taken up by all notes in the measure.\n",
    "        # Calculate any residual time to see if this measure (in 4/4 time) is longer than 1 measure.\n",
    "        measure_time = time + beat_time\n",
    "        leftover_time = (measure_time) % 1\n",
    "\n",
    "        # If the measure count (i.e., the measure integer) has changed and there is significant left-over beat time:\n",
    "        if (int(measure_time) > int(time)) and (leftover_time > 1/128):\n",
    "\n",
    "            # Calculate the initial 32nd notes encompassed by this beat in the current measure.\n",
    "            this_measure_thirty_seconds = int(32 * (1 - time % 1))\n",
    "            # Calculate the remaining 32nd notes encompassed by this beat in the next measure.\n",
    "            next_measure_thirty_seconds = int(32 * leftover_time)\n",
    "\n",
    "            # Get the Duration object parameters for this measure and the next measure.\n",
    "            this_measure_durations = quantize_thirty_seconds(this_measure_thirty_seconds)\n",
    "            next_measure_durations = quantize_thirty_seconds(next_measure_thirty_seconds)\n",
    "\n",
    "\n",
    "            #print(f'{{ {32 / beat[1]}')\n",
    "            for duration_idx, duration in enumerate(this_measure_durations):\n",
    "                time += (1 / duration[0]) * (1 + 0.5 * duration[1])\n",
    "\n",
    "                #print(time, '\\t', time * 32)\n",
    "\n",
    "                chord = beat[0] if duration_idx == 0 else 'tied'\n",
    "\n",
    "                new_prediction_output.append((chord, duration[0], duration[1]))\n",
    "\n",
    "\n",
    "            for duration in next_measure_durations:\n",
    "                time += (1 / duration[0]) * (1 + 0.5 * duration[1])\n",
    "\n",
    "                #print(time, '\\t', time * 32)\n",
    "\n",
    "                new_prediction_output.append(('tied', duration[0], duration[1]))\n",
    "\n",
    "\n",
    "            continue\n",
    "\n",
    "\n",
    "        time += beat_time\n",
    "        new_prediction_output.append((beat[0], beat[1], beat[2]))\n",
    "\n",
    "        #print(time, '\\t', time * 32)\n",
    "\n",
    "\n",
    "    '''\n",
    "    # Code for debugging\n",
    "    \n",
    "    time = 0\n",
    "    time2 = 0\n",
    "    idx = 0\n",
    "\n",
    "    for idx2, beat2 in enumerate(new_prediction_output[:100]):\n",
    "        beat = prediction_output[idx]\n",
    "\n",
    "        if time == time2:\n",
    "            print(beat[0], '\\t', time, '\\t\\t', beat2[0], '\\t', time2)\n",
    "\n",
    "            idx += 1\n",
    "\n",
    "            time += (1 / beat[1]) * (1 + 0.5 * beat[2])\n",
    "\n",
    "        else:\n",
    "            print('\\t\\t\\t\\t', beat2[0], '\\t', time2)\n",
    "\n",
    "\n",
    "\n",
    "        time2 += (1 / beat2[1]) * (1 + 0.5 * beat2[2])\n",
    "    ''';\n",
    "    \n",
    "    # Use the previously calculated cumulative time as the number of measures in the new 4/4 song.\n",
    "    num_measures = int(np.ceil(time))\n",
    "\n",
    "    song = np.empty(num_measures, dtype=object)\n",
    "\n",
    "    time = 0\n",
    "    m_idx = 0\n",
    "\n",
    "    timestamps = []\n",
    "\n",
    "    for beat in new_prediction_output:\n",
    "        #print(time)\n",
    "        timestamps.append(time)\n",
    "\n",
    "        m_idx = int(time)\n",
    "\n",
    "        if song[m_idx] is None:\n",
    "\n",
    "            song[m_idx] = [beat]\n",
    "        else:\n",
    "            song[m_idx].append(beat)\n",
    "\n",
    "\n",
    "        time += (1 / beat[1]) * (1 + 0.5 * beat[2])\n",
    "\n",
    "\n",
    "    print(f'4/4 adjusted correctly: {set(range(num_measures)).issubset(set(timestamps))}')\n",
    "    \n",
    "    return song"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0ac63c-8deb-4bce-9f7e-e098149e22f1",
   "metadata": {},
   "source": [
    "## Figure out the necessary guitar tunings for the produced tracks, then save all tracks together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ada3fb31-b919-438b-bb74-b4fff952c064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 adjusted correctly: True\n",
      "4/4 adjusted correctly: True\n",
      "4/4 adjusted correctly: True\n",
      "4/4 adjusted correctly: True\n",
      "4/4 adjusted correctly: True\n",
      "4/4 adjusted correctly: True\n",
      "4/4 adjusted correctly: True\n",
      "4/4 adjusted correctly: True\n",
      "4/4 adjusted correctly: True\n",
      "4/4 adjusted correctly: True\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "songWriter = SongWriter(initialTempo=track_data.loc[track_indices[0]]['tempo'])\n",
    "\n",
    "for idx in range(len(tracks)):\n",
    "    new_track = adjust_to_4_4(tracks[idx])\n",
    "\n",
    "    # Get the tempo and tuning (lowest string note) of the song:\n",
    "    #print(          track_data.loc[track_indices[idx]])\n",
    "    tempo         = track_data.loc[track_indices[idx]]['tempo']\n",
    "    instrument    = track_data.loc[track_indices[idx]]['instrument'] \n",
    "    name          = track_data.loc[track_indices[idx]]['song']\n",
    "    lowest_string = track_data.loc[track_indices[idx]]['tuning']\n",
    "\n",
    "    if not as_fingerings:\n",
    "        # Get all the unique pitch values from the new track\n",
    "        pitchnames = set.union(*[set([beat[0].split('_')[0] for beat in measure]) for measure in new_track])\n",
    "        pitchnames.discard('rest') # Ignore rests\n",
    "        pitchnames.discard('tied') # Ignore tied notes\n",
    "        pitchnames.discard('dead') # Ignore dead/ghost notes\n",
    "        lowest_string = min([MIDI[pitch] for pitch in pitchnames]) # Get the lowest MIDI value / pitch\n",
    "        lowest_string = min(lowest_string, MIDI['E2']) # Don't allow any tunings higher than standard.\n",
    "\n",
    "\n",
    "    # Standard tuning\n",
    "    tuning = {1: MIDI['E4'],\n",
    "              2: MIDI['B3'],\n",
    "              3: MIDI['G3'],\n",
    "              4: MIDI['D3'],\n",
    "              5: MIDI['A2'],\n",
    "              6: MIDI['E2']}\n",
    "\n",
    "    if lowest_string <= MIDI['B1']:\n",
    "        # 7-string guitar case\n",
    "        tuning[7] = MIDI['B1']\n",
    "        downtune = MIDI['B1'] - lowest_string\n",
    "    else:\n",
    "        # downtune the tuning by however much is necessary.\n",
    "        downtune = MIDI['E2'] - lowest_string\n",
    "\n",
    "    tuning = {k: v - downtune for k, v in tuning.items()} # Adjust to the new tuning\n",
    "    \n",
    "    # Write the track to the song writer\n",
    "    songWriter.decompress_track(new_track, tuning, tempo=tempo, instrument=instrument, name=name, as_fingerings=as_fingerings)\n",
    "    \n",
    "    \n",
    "    \n",
    "songWriter.write('_generation.gp5')\n",
    "print('Finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
