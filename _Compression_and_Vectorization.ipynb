{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1387f93-eb54-4b6d-9dad-2db5d4c4c8d6",
   "metadata": {
    "id": "e1387f93-eb54-4b6d-9dad-2db5d4c4c8d6",
    "tags": []
   },
   "source": [
    "# Step 1: Compression and Vectorization of Songs\n",
    "\n",
    "References: \n",
    "\n",
    "https://github.com/shubham3121/music-generation-using-rnn \n",
    "\n",
    "https://www.hackerearth.com/blog/developers/jazz-music-using-deep-learning/\n",
    "\n",
    "https://pyguitarpro.readthedocs.io/en/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad10df5b-4fd9-4d25-9bb4-577d91d4631d",
   "metadata": {
    "id": "55d3a53d-b08f-4edc-a37c-faa5a41051aa"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87a0d6de-23af-4d2b-a938-e38414a4f9dc",
   "metadata": {
    "id": "b4e83e4a-1a78-4c3e-8e94-d1e1a13637ef"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import guitarpro\n",
    "from guitarpro import *\n",
    "from matplotlib import pyplot as plt\n",
    "import mgzip\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from _Compressor import compress_track\n",
    "from _NoteData import NoteData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f786431-dcb9-4aa2-a15a-3d1b3b9750e7",
   "metadata": {},
   "source": [
    "## Constants / Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47f54110-81c4-4768-bb3a-f1ee20e4f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIDI  = {str(GuitarString(number=0, value=val)) : val for val in range(128)}\n",
    "\n",
    "as_fingerings = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a7601c-c62b-4d94-abf1-e52b65d23389",
   "metadata": {},
   "source": [
    "## Choose Songs (Make sure to convert to 4/4 before running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d95c988-10fa-4456-bf15-8349a3a650bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a certain cohort of songs\n",
    "\n",
    "\n",
    "filenames = glob('songs\\\\*.gp5')\n",
    "#filenames = glob('songs\\\\pantera*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff40e369-6410-4f53-a438-86b40d952e52",
   "metadata": {},
   "source": [
    "## Compress Each Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9eb58a9-5756-47f1-ae86-74bd16d107e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_name(filename):\n",
    "    \n",
    "    band_name = filename.split('\\\\')[-1].split('-')[0] # Isolate the band's name from the filepath\n",
    "    \n",
    "    band_name = string.capwords(band_name.replace('_', ' ')) # Remove underscores and capitalize each word\n",
    "    \n",
    "    return band_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc55d8d5-63aa-42f3-85c3-46f1fb03201b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134/134 [01:46<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tracks: 684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "compressed_tracks = []\n",
    "\n",
    "track_data = []\n",
    "\n",
    "for filename in tqdm(filenames):\n",
    "    song = guitarpro.parse(filename)\n",
    "    \n",
    "    for track in song.tracks:\n",
    "        #print(track.name, track.channel.instrument)\n",
    "        \n",
    "        # Filter out percussion tracks and other SFX or drum-related tracks.\n",
    "        if track.isPercussionTrack or track.channel.instrument >= 113:\n",
    "            continue\n",
    "            \n",
    "        compressed_track = compress_track(track, as_fingerings)\n",
    "\n",
    "        # Ignore the current track if it only contains rests.\n",
    "        if all(all(beat[0] == 'rest' for beat in measure) for measure in compressed_track):\n",
    "            continue\n",
    "            \n",
    "        compressed_tracks.append(compressed_track)\n",
    "        \n",
    "        track_data.append({})\n",
    "        track_data[-1]['artist'] = get_artist_name(filename)\n",
    "        if song.title == '' or song.title is None:\n",
    "            song.title = string.capwords(filename.split('-')[-1].split('.')[0].replace('_', ' '))\n",
    "        track_data[-1]['song'] = song.title\n",
    "        track_data[-1]['name'] = track.name\n",
    "        track_data[-1]['instrument'] = track.channel.instrument\n",
    "        track_data[-1]['tempo'] = song.tempo\n",
    "        track_data[-1]['tuning'] = track.strings[-1].value\n",
    "\n",
    "\n",
    "print(f'Number of tracks: {len(compressed_tracks)}')\n",
    "track_data = pd.DataFrame(track_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd0ebed-255c-4f51-97c9-42561861c53e",
   "metadata": {},
   "source": [
    "## Compile Note Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4783e65-55e0-4e71-a9dc-6f352d7f1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if type(x) != str:\n",
    "        x = int_to_note[x][0]\n",
    "        \n",
    "    if x == 'rest' or x == 'tied':\n",
    "        return -2\n",
    "    if x == 'dead':\n",
    "        return -1\n",
    "    \n",
    "    if as_fingerings:\n",
    "        return int(x.split('_')[0])\n",
    "    else:\n",
    "        return MIDI[x.split('_')[0]]\n",
    "\n",
    "def sort(x):\n",
    "    semitones = f(x[0])\n",
    "    duration = int((32 // x[1]) * (1 + 0.5 * x[2]))\n",
    "    \n",
    "    return (semitones, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a43df549-4e6b-4e82-a27b-6564d371afd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 684/684 [00:00<00:00, 1937.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of notes played:\t 544773\n",
      "Number of unique notes:\t 1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "notes = []\n",
    "notes_set = set()\n",
    "\n",
    "note_start_indices = []\n",
    "\n",
    "\n",
    "for i, compressed_track in enumerate(tqdm(compressed_tracks)):\n",
    "    \n",
    "    note_start_indices.append(len(notes))\n",
    " \n",
    "    # Iterate through each measure in each compressed track\n",
    "    for measure in compressed_track:\n",
    "        \n",
    "        keep = True\n",
    "        \n",
    "        # Skip measures that are only rests.\n",
    "        if all(beat[0] == 'rest' for beat in measure):\n",
    "            keep = False\n",
    "        \n",
    "        # Add each measure's notes to the notes list\n",
    "        for beat in measure:\n",
    "            notes_set.add(beat)\n",
    "            if keep:\n",
    "                notes.append(beat)\n",
    "                \n",
    "                \n",
    "notes_set = notes_set\n",
    "n_vocab = len(notes_set)\n",
    "\n",
    "note_to_int = dict((note, number) for number, note in enumerate(sorted(notes_set, key=lambda x: sort(x))))\n",
    "int_to_note = {v: k for k, v in note_to_int.items()} # Invert the map\n",
    "    \n",
    "print(f'Number of notes played:\\t {len(notes)}')\n",
    "print(f'Number of unique notes:\\t {n_vocab}')\n",
    "\n",
    "track_data['noteStartIdx'] = note_start_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d38d3bf-5b32-4ef3-9785-286de981e7e7",
   "metadata": {},
   "source": [
    "## Get some patterns in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccc55425-8978-4f8a-8c30-28751a891777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 most common values:\n",
      "[#Semitones, duration, isDotted]\n",
      "\n",
      "5.3% \t 0,\t 1/8, \n",
      "3.9% \t 0,\t 1/16, muted\n",
      "3.2% \t 0,\t 1/16, \n",
      "3.1% \t 0,\t 1/8, muted\n",
      "2.3% \t rest,\t 1/8, \n",
      "1.7% \t tied,\t 1/8, \n",
      "1.6% \t 3,\t 1/8, \n",
      "1.5% \t 2,\t 1/16, \n",
      "1.4% \t 0_5,\t 1/8, \n",
      "1.4% \t 1,\t 1/8, \n",
      "1.4% \t 2,\t 1/8, \n",
      "1.3% \t 12,\t 1/8, \n",
      "1.3% \t 3,\t 1/16, \n",
      "1.3% \t 7,\t 1/8, \n",
      "1.3% \t 5,\t 1/8, \n"
     ]
    }
   ],
   "source": [
    "vals, freq = np.unique([note_to_int[x] for x in notes], return_counts=True)\n",
    "\n",
    "vals = np.array([int_to_note[x] for x in vals])\n",
    "freq = 100 * freq / freq.sum()\n",
    "\n",
    "\n",
    "sort_idx = freq.argsort()[::-1]\n",
    "\n",
    "print('Top 15 most common values:')\n",
    "print('[#Semitones, duration, isDotted]\\n')\n",
    "for idx in sort_idx[:15]:\n",
    "    noteData = NoteData(vals[idx][0], int(vals[idx][1]), vals[idx][2] == 'True', vals[idx][3] == 'True')\n",
    "    #print(f'{vals[idx]} \\t {freq[idx] :.1f}%')\n",
    "    print(f'{freq[idx] :.1f}% \\t {str(noteData)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21cd9aa-1505-46c5-81fb-cbe2ede7036a",
   "metadata": {},
   "source": [
    "## Data Compression and Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0af307cf-c20b-473c-918d-154253b13856",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00fd9201-0a45-4835-a525-5132f86bebb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with mgzip.open('data\\\\notes_data.pickle.gz', 'wb') as filepath:\n",
    "    pickle.dump(notes, filepath)\n",
    "    pickle.dump(note_to_int, filepath)\n",
    "    pickle.dump(int_to_note, filepath)\n",
    "    pickle.dump(n_vocab, filepath)\n",
    "    \n",
    "with mgzip.open('data\\\\track_data.pickle.gz', 'wb') as filepath:\n",
    "    pickle.dump(track_data, filepath)\n",
    "\n",
    "# How to read DataFrame pickles:\n",
    "# pd.read_pickle('track_data.pickle')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Metal Music Sampling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
